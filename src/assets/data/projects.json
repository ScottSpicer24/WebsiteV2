
[
    {
        "Name": "Trip Buddy",
        "Description": "Agentic AI travel planning web application that autonomously researches transportation, lodging, dining, and activities based on natural language user input, presents curated options, and books selected travel arrangements while providing real-time assistance through a fine-tuned multimodal language model.",
        "Overview": "Agentic AI travel planning web application.",
        "Contributions": ["Engineered a multi-node agentic system to plan an itinerary using LangChain.", "Integrated OpenRouter LLMs with tool-calling pipelines for dynamic web searching. Utilizing search, page navigation, scraping, and OCR.", "Created robust data validation pipelines to ensure quality input and outputs."],
        "VisualPath": "assets/project/TripBuddy.png",
        "VideoPath": null,
        "Tools": ["Python"],
        "ToolsVisualPath": ["icons/python-240.png"],
        "OtherTools" : ["LangChain", "OpenRouter", "FastAPI", "Next.js", "Supabase"]
    },
    {
        "Name": "OmniToM",
        "Description": "Developed a novel Theory of Mind benchmark dataset by generating and annotating ~20,000 structured beliefs across ~900 stories using a multi-model LLM pipeline, applying a psychology-grounded annotation framework and experimentally optimizing belief extraction and labeling through systematic prompting and cross-model evaluation.",
        "Overview": "A novel theory of mind benchmark dataset.",
        "Contributions": ["Researched Theory of Mind papers across both computer science and social science.", "Wrote scripts to run experiments on belief extraction, belief annotation, or both. Scripts formatted the output and saved the raw output as well for QA.", "Scripts could dynamically change between models, task, story types, amount of stories, prompts, and output format with input parameters.", "Wrote batch scripts, utilized GPU and CPU clusters to run experiments in parallel across dozens of models and various permutations of input parameters across all 3 tasks."],
        "VisualPath": "assets/project/OmniToM.png",
        "VideoPath": null,
        "Tools": ["Python"],
        "ToolsVisualPath": ["icons/python-240.png"],
        "OtherTools" : ["Batch", "OpenRouter", "OpenAI", "Slurm"]
    },
    {
        "Name": "LLaVA Med",
        "Description": "Trained a LLaVA-style model for multiple choice medical visual question answering. Fine-tuned on 20k image-question pairs from the open-source PMC-VQA dataset. This imporved the accuracy compared to baseline by 15%. Made a UI and hosted the model for demo purposes at medllava.scottspicer.com",
        "Overview": "Fine-Tuned then deployed a LLaVA model to answer medical questions. Hosted at medllava.scottspicer.com",
        "Contributions": null,
        "VisualPath": null,
        "VideoPath": null,
        "Tools": ["Python", "Hugging Face", "PyTorch"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/hugging-face-240.png","icons/pytorch-240.png"],
        "OtherTools" : ["Angular", "AWS", "Numpy", "Google Colab", "Kaggle Notebooks"]
    },
    {
        "Name": "BIAS 101",
        "Description": "UCF-101 is a widely used action-recognition dataset, but its original videos show significant bias across age, gender, race, hair color, and body type. Working in a team of four, we mitigated these biases by adding carefully-selected counterfactual videos, which reduced the χ² (chi-squared) imbalance score and the dominance ratio.",
        "Overview": "Expanded and debias the UCF-101 action-recognition video dataset.",
        "Contributions": ["Reviewed state-of-the-art techniques for debiasing video datasets and shaped the team's methodology.", "Wrote a Python script that detects scene changes and automatically splits videos into granular clips for analysis.", "Integrated an activity-verification model to confirm that each new clip still depicts the intended action class.", "Performed manual QA on clips to validate action labels and bias tags, ensuring high data quality."],
        "VisualPath": "assets/project/bias-101-workflow.png",
        "VideoPath": null,
        "Tools": ["Python", "Hugging Face", "NumPy", "PyTorch"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/hugging-face-240.png", "icons/numpy-240.png", "icons/pytorch-240.png"],
        "OtherTools" : ["Google Colab", "OpenCV", "MoviePy"]
    },
    {
        "Name": "Unit Test Gap Filler",
        "Description": "Built a two-stage pipeline of pre-trained AI models that automatically detects gaps in software unit tests and then generates the missing test cases. The first model pinpoints untested code paths, while the second synthesizes the necessary inputs, expected outputs, and test code. I evaluated four model pairings on OpenAI's HumanEval benchmark and selected the configuration that delivered the highest coverage and reliability. The best pairing (Deepseek-R1 and Qwen2.5 Coder) improved line coverage by 41%.",
        "Overview": "Built a pipeline of AI models to find an fill gaps in unit testing.",
        "Contributions": null,
        "VisualPath": null,
        "VideoPath": null,
        "Tools": ["Python", "Hugging Face", "NumPy", "PyTorch"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/hugging-face-240.png", "icons/numpy-240.png", "icons/pytorch-240.png"],
        "OtherTools" : ["Google Colab"]
    },
    {
        "Name": "MiSu",
        "Description": "Mi casa es Su casa, my senior design project, was a smart home app that allows users to control all their smart devices and securely share access with guests. Users retain complete control over what actions guests can perform and when. Our team was responsible for version 4 of the app, which previously had not been maintained for two years. Due to extensive deprecations, we performed a full rebuild, improving data flow, management, and user experience.",
        "Overview": "Rebuilt a smart home app that allows users to control all their smart devices and securely share access with guests.",
        "Contributions": ["Led AWS cloud engineering efforts for the team.", "Tested, debugged, and replaced deprecated Lambda functions and REST APIs.", "Designed and implemented WebSocket solutions to optimize real-time data flow.", "Aided in adding new features, including guest access requests and real-time log updates."],
        "VisualPath": null,
        "VideoPath": "assets/project/Misu8min.mp4",
        "Tools": ["AWS", "React"],
        "ToolsVisualPath": ["icons/aws-256.png", "icons/react-160.png"],
        "OtherTools" : ["Home Assistant", "Raspberry Pi", "Node.JS", "Expo", "Jira"]
    },
    {
        "Name": "CLEAR",
        "Description": "This study compared AI-based and traditional video denoisers using the UCF-101 dataset, focusing on denoising performance across four noise types: Gaussian, Salt-and-Pepper, Poisson, and Speckle. Metrics such as PSNR, SSIM, VIF are used to evaluate denoising quality, while computational efficiency is measured through processing time per frame. The results reveal that AI-based denoisers like VRT excel in complex noise restoration but require substantial computational resources, whereas traditional denoisers demonstrate better efficiency at the cost of quality. ",
        "Overview": "A study with 4 others that compared AI-based and traditional video denoisers on 4 noise types across 3 metrics.",
        "Contributions": ["Applied four distinct noise types to over 13,000 videos, each ranging from 3 to 7 minutes in length.", "Researched and optimized hyperparameter settings for the Fast Non-Local Means function through extensive testing.", "Analyzed denoised videos, generated performance metrics and visualizations, and presented findings effectively."],
        "VisualPath": null,
        "VideoPath": null,
        "Tools": ["Python", "Hugging Face", "NumPy", "PyTorch"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/numpy-240.png", "icons/pytorch-240.png"],
        "OtherTools" : ["OpenCV", "Slurm"]
    },
    {
        "Name": "Song Year Classifier",
        "Description": "Developed a feature tokenizer transformer AI model to classify the year of songs, spanning nearly a century (1922-2011), using a subset of the Million Song Dataset. The model was trained on a large-scale dataset of 500,000 rows, each with 90 attributes and corresponding labels. Utilized GPU acceleration to expedite model training on the UCF Newton GPU cluster. Tuned hyperparameters to improve model performance. Achieved a test accuracy of 66%, demonstrating the model's ability to predict song release years with reasonable accuracy. ",
        "Overview": "Created an FT-Transformer to classify the year of the song.",
        "Contributions": null,
        "VisualPath": null,
        "VideoPath": "assets/project/song_classifier_presentation.mp4",
        "Tools": ["Python", "NumPy", "PyTorch"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/numpy-240.png", "icons/pytorch-240.png"],
        "OtherTools" : ["Scikit-Learn", "Slurm"]
    },
    {
        "Name": "Spicy Fitness",
        "Description": "Summer 2024 Solo project. One day in the gym I realized that there had to be a better way to track my workouts. After looking at a few that didn't have what I wanted, I decided to build my own. This way, I could easily have log progressive overload from day to day while having the flexibility to adapt quickly and seemlessly on the fly. React Native front-end and AWS serverless back-end.",
        "Overview": "Created a fitness tracking mobile app to log workouts and track results.",
        "Contributions": null,
        "VisualPath": null, 
        "VideoPath": "assets/project/FitnessAppDemo.mp4",
        "Tools": ["React", "AWS"],
        "ToolsVisualPath": ["icons/react-160.png", "icons/aws-256.png"],
        "OtherTools" : ["Node.JS", "Expo"]
    },
    {
        "Name": "Online Chess",
        "Description": "Our team of 4 developed an online multiplayer chess application that allows users to manage accounts, add and interact with friends, track elo scores, and play chess matches in real-time. ",
        "Overview": "Created a windows desktop app to play chess online with friends.",
        "Contributions": ["Designed and implemented the game engine and its accompanying API for the chess game.", "Conducted extensive testing of game engine logic to ensure compliance with official chess rules.", "Aided in the integration of my chess engine with the rest of the system.", "Set up the AWS infrastructure, including an EC2 instance, to enable WebSocket connections for real-time gameplay."],
        "VisualPath": null,
        "VideoPath": null,
        "Tools": [".NET", "C#"],
        "ToolsVisualPath": ["icons/net-framework-240.png", "icons/c-sharp-logo-2-240.png"],
        "OtherTools" : ["AWS"]
    },
        {
        "Name": "Wordle",
        "Description": "This was the first application I made with both a front-end and a back-end, and the first time making a front-end at all. This project, utilizing Flask and Bootstrap, helped me get a better understanding of how real software works.",
        "Overview": "My first full application I made, it was a wordle clone web app.",
        "Contributions": null,
        "VisualPath": null,  
        "VideoPath": "assets/project/WordleDemoVid.mp4",
        "Tools": ["Python", "HTML/CSS"],
        "ToolsVisualPath": ["icons/python-240.png", "icons/html5-240.png"],
        "OtherTools" : ["Flask", "Bootstrap"]
    }
]